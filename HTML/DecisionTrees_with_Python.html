<HTML>
<head>
<body style="background-color:#F6F5F5;">

<style>

.container{
    display: flex;
    flex-direction: column;
}

ibody{
    margin:0;
    min-height: 100%;
    min-width:100%;
    
}


body {
	font-family: verdana;
    background-color : #F6F5F5 ;
    position : relative
    style: #232435;

}

.navbar{
    top:0;
    position: fixed;
    width : 100%;
    
}

.topnav {
  overflow: hidden;
  background-color: #1F1A40;
}

.topnav a {
  float: left;
  color: #BBD8F2;
  text-align: center;
  padding: 12px 14px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #D3E0EA;
  color: black;
}

.topnav a.active {
  background-color: #FFFFFF;
  color: white;
}

.headerLogo{
  top:200px;
  height:250px;
  width:200px;
  line-height:200px;

  overflow:hidden;
 
  <!-- top:200px; height:900px; width:1450px; line-height:500px -->
}
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 100%;
}

h1 {text-align: left;}
p {text-align: justify;
    text-justify: inter-word;
}
div {text-align: left;}

.content{
    margin-left:0;
    padding : 2% 25% 2% 25%;
}

ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
    overflow: hidden;
    background-color: #34495E;
    max-width:1500px;
}

li {
    float: left;
}

li a, .dropbtn {
    display: inline-block;
    color: white;
    text-align: center;
    padding: 14px 16px;
    text-decoration: none;
}

li a:hover, .dropdown:hover .dropbtn {
    background-color: grey;
}

li.dropdown {
    display: inline-block;
}

.dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 160px;
    
    
}

.dropdown-content a {
    color: black;
    padding: 12px 16px;
    text-decoration: none;
    display: block;
    text-align: left;
    
}



.dropdown:hover .dropdown-content {
    display: block;
    opacity: 1;
}
td {
    padding: 5px;
    text-align: left;
    width: 500px;
}

tr{
   padding: 0px;
   text-align: top;
   background-color:#ffffff
}

img:hover {
  opacity: 1;
}

</style>

<div class="container">
<div class = "navbar">
<ul>
    
   <li><a href="https://sonalipednekar.netlify.app/" >  About Me </a></li>
    
    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/Introduction.html" >  Introduction </a> </li>
    
    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/DataGathering.html" >  Data Gathering </a></li>
    
    
    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/DataCleaning.html" >  Data Cleaning </a></li>
    
    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/ExploringData.html" >  Exploring Data </a></li>
    
    <li class="dropdown">
        <a href="javascript:void(0)" class="dropbtn">Clustering</a>
    
        <div class="dropdown-content">
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/Clustering_with_R.html" >Clustering in R</a>
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/Cluster_with_Python.html" >Clustering in Python</a>
        </div>
    </li>

    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/ARMandNetworking.html" >  ARM and Networking </a></li>
    
    <li class="dropdown">
        <a href="javascript:void(0)" class="dropbtn">Decision Trees</a>
    
        <div class="dropdown-content">
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/DecisionTrees_with_R.html" >Decision Trees in R</a>
        <a href="#Decision Trees with Python">Decision Trees in Python</a>
        </div>
    </li>
    
    <li class="dropdown">
        <a href="javascript:void(0)" class="dropbtn">Naive Bayes</a>
    
        <div class="dropdown-content">
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/NaiveBayes_with_R.html" >NaiveBayes in R</a>
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/NaiveBayes_with_Python.html" >NaiveBayes in Python</a>
        </div>
    </li>
    
    
    <li class="dropdown">
        <a href="javascript:void(0)" class="dropbtn">SVM</a>
    
        <div class="dropdown-content">
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/SVM_with_R.html" >SVM in R</a>
        <a href="https://sonalipednekar.georgetown.domains/ANLY501/SVM_with_Python.html" >SVM in Python</a>
        
        </div>
    </li>
   
    <li><a href="https://sonalipednekar.georgetown.domains/ANLY501/Conclusions.html" >  Conclusions </a></li>
    
    
    
</div>
</ul>
<div class="content">
<div class="w3-container w3-border city" id="Decision Trees" >
<h1><center><b>Decision Trees</b></center></h1>
<p><center>This page contains the Decision Trees code and visualizations done in in Python for Text data. 

<h3><b>What are Decision Trees</b></h3>
<p> Decision Trees (DTs) are a supervised learning technique that predict values of responses by learning decision rules derived from features. They can be used in both a regression and a classification context. For this project, decision trees are used in the classification context. Decision tree learning is a method commonly used in data mining. The goal is to create a model that predicts the value of a target variable based on several input variables. 
<br>			

<h2><b>Decision Trees in Python</b></h2>
<p> The decision trees are created using text dataset in Python.The tweets are extracted on the hashtag "social worker" and hashtag "covid" . The motive behind collecting this text data was to understand the opinion of people regarding social work and different tweets regarding covid. To get a quick overview of the data, a wordcloud has been made.</p>
<img alt="twitter_wordcloud.jpg" height="400px" src="twitter_wordcloud.jpg" width="600px" />
&emsp;
&emsp;
<img alt="word_python.jpg" height="400px" src="word_python.jpg" width="600px" />

<h3><b>Cleaning and formatting the dataset to the required format</b></h3>
<p>There are a lot of unwated columns in the dataframe. These columns are dropped from the dataframe, retaining only the necessary columns. The stopwords are removed and the text is tokenized, lemmatized and stemmed. Countvectorizer is applied on the data to convert it to numerical format. Checking the balance of the label is very important before performing decision trees, as unbalanced dataset may lead to over or underfitting.  </p>
<p><center>The snapshot of the dataset and the link to the csv file is attached below.</center></p>
<center><img alt="dt_twitter_small.jpg" height="400px" src="dt_twitter_small.jpg" width="600px" /></center>
			<center><a href="dt_twitter.jpg" target="new">View </a></center>
			<a href="dt_twitter.jpg" target="new"> </a>

			<center><a href="https://sonalipednekar.georgetown.domains/ANLY501/twitter_file_dt.csv">Download csv file</a></center>
<center><img alt="dtm_cv_small.jpg" height="400px" src="dtm_cv_small.jpg" width="600px" /></center>
			<center><a href="dtm_cv.jpg" target="new">View </a></center>
			<a href="dtm_cv.jpg" target="new"> </a>

			<center><a href="https://sonalipednekar.georgetown.domains/ANLY501/DTM_CV_DT.csv">Download csv file</a></center>

<h3><b>Model Building</b></h3>
<p> The code to build the model can be found <a href="https://sonalipednekar.georgetown.domains/ANLY501/DecisionTreesTweets.py" target="_blank">here</a> </p>
<p>Before building the model, the dataset is split into training and testing sets. The split ratio is 0.75 of the total data in the training set and 0.25 data in the testing set. Three different decision trees are created. The Decision Trees differ due to hypertuning of different parameters. Mainly criterion (entropy, gini), splitter (best, random) ,max_depth is tuned. </p>

<p><b> Decision Tree 1</b></p>
<p>This is the first decision tree. In this tree the hyperparameter are criterion = "entropy", splitter = "best",max_depth = 4. In this tree, the accuracy is 88%.</p>
<p><center>The snapshot of the decision tree and the accuracy/heatmap is attached below. </center></p>
<img alt="dtp1.jpg" height="400px" src="dtp1.jpg" width="600px" />
&emsp;
&emsp;
<img alt="hm1.jpg" height="400px" src="hm1.jpg" width="600px" />

<p><b> Decision Tree 2</b></p>
<p>This is the second decision tree. In this tree the hyperparameter are criterion = "entropy", splitter = "best",max_depth = 4. In this tree, the accuracy is 88%. </p>
<p><center>The snapshot of the decision tree and the accuracy/heatmap is attached below. </center></p>
<img alt="dtp2.jpg" height="400px" src="dtp2.jpg" width="600px" />
&emsp;
&emsp;
<img alt="hm2.jpg" height="400px" src="hm2.jpg" width="600px" />

<p><b> Decision Tree 3</b></p>
<p>This is the third decision tree. In this tree the hyperparameter are criterion = "entropy", splitter = "best",max_depth = 4. In this tree, the accuracy is 85%. </p>
<p><center>The snapshot of the decision tree and the accuracy/heatmap is attached below.</center></p>
<img alt="dtp3.jpg" height="400px" src="dtp3.jpg" width="600px" />
&emsp;
&emsp;
<img alt="hm3.jpg" height="400px" src="hm3.jpg" width="600px" />




</div>








</HTML>


